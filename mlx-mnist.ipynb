{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30615,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"To install from PyPI you must meet the following requirements:\n\n> Using an M series chip (Apple silicon)\n> \n> Using a native Python >= 3.8\n> \n> MacOS >= 13.3","metadata":{}},{"cell_type":"code","source":"import gzip\nimport numpy as np\nimport os\nimport pickle\nfrom urllib import request\n\n\ndef mnist(save_dir=\"/tmp\"):\n    \"\"\"\n    Load the MNIST dataset in 4 tensors: train images, train labels,\n    test images, and test labels.\n\n    Checks `save_dir` for already downloaded data otherwise downloads.\n\n    Download code modified from:\n      https://github.com/hsjeong5/MNIST-for-Numpy\n    \"\"\"\n\n    def download_and_save(save_file):\n        base_url = \"http://yann.lecun.com/exdb/mnist/\"\n        filename = [\n            [\"training_images\", \"train-images-idx3-ubyte.gz\"],\n            [\"test_images\", \"t10k-images-idx3-ubyte.gz\"],\n            [\"training_labels\", \"train-labels-idx1-ubyte.gz\"],\n            [\"test_labels\", \"t10k-labels-idx1-ubyte.gz\"],\n        ]\n\n        mnist = {}\n        for name in filename:\n            out_file = os.path.join(\"/tmp\", name[1])\n            request.urlretrieve(base_url + name[1], out_file)\n        for name in filename[:2]:\n            out_file = os.path.join(\"/tmp\", name[1])\n            with gzip.open(out_file, \"rb\") as f:\n                mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(\n                    -1, 28 * 28\n                )\n        for name in filename[-2:]:\n            out_file = os.path.join(\"/tmp\", name[1])\n            with gzip.open(out_file, \"rb\") as f:\n                mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n        with open(save_file, \"wb\") as f:\n            pickle.dump(mnist, f)\n\n    save_file = os.path.join(save_dir, \"mnist.pkl\")\n    if not os.path.exists(save_file):\n        download_and_save(save_file)\n    with open(save_file, \"rb\") as f:\n        mnist = pickle.load(f)\n\n    preproc = lambda x: x.astype(np.float32) / 255.0\n    mnist[\"training_images\"] = preproc(mnist[\"training_images\"])\n    mnist[\"test_images\"] = preproc(mnist[\"test_images\"])\n    return (\n        mnist[\"training_images\"],\n        mnist[\"training_labels\"].astype(np.uint32),\n        mnist[\"test_images\"],\n        mnist[\"test_labels\"].astype(np.uint32),\n    )\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-11T05:49:16.465091Z","iopub.execute_input":"2023-12-11T05:49:16.465524Z","iopub.status.idle":"2023-12-11T05:49:17.718062Z","shell.execute_reply.started":"2023-12-11T05:49:16.465492Z","shell.execute_reply":"2023-12-11T05:49:17.716755Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_x, train_y, test_x, test_y = mnist()","metadata":{"execution":{"iopub.status.busy":"2023-12-11T06:01:05.555836Z","iopub.execute_input":"2023-12-11T06:01:05.556275Z","iopub.status.idle":"2023-12-11T06:01:05.761091Z","shell.execute_reply.started":"2023-12-11T06:01:05.556238Z","shell.execute_reply":"2023-12-11T06:01:05.759428Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install -U mlx","metadata":{"execution":{"iopub.status.busy":"2023-12-11T06:07:42.474166Z","iopub.execute_input":"2023-12-11T06:07:42.474582Z","iopub.status.idle":"2023-12-11T06:07:45.007017Z","shell.execute_reply.started":"2023-12-11T06:07:42.474542Z","shell.execute_reply":"2023-12-11T06:07:45.004903Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement mlx (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for mlx\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import argparse\nimport time\n\nimport numpy as np\n\nimport mlx.core as mx\nimport mlx.nn as nn\nimport mlx.optimizers as optim\n\nimport mnist\n\n\nclass MLP(nn.Module):\n    \"\"\"A simple MLP.\"\"\"\n\n    def __init__(\n        self, num_layers: int, input_dim: int, hidden_dim: int, output_dim: int\n    ):\n        super().__init__()\n        layer_sizes = [input_dim] + [hidden_dim] * num_layers + [output_dim]\n        self.layers = [\n            nn.Linear(idim, odim)\n            for idim, odim in zip(layer_sizes[:-1], layer_sizes[1:])\n        ]\n\n    def __call__(self, x):\n        for l in self.layers[:-1]:\n            x = mx.maximum(l(x), 0.0)\n        return self.layers[-1](x)\n\n\ndef loss_fn(model, X, y):\n    return mx.mean(nn.losses.cross_entropy(model(X), y))\n\n\ndef eval_fn(model, X, y):\n    return mx.mean(mx.argmax(model(X), axis=1) == y)\n\n\ndef batch_iterate(batch_size, X, y):\n    perm = mx.array(np.random.permutation(y.size))\n    for s in range(0, y.size, batch_size):\n        ids = perm[s : s + batch_size]\n        yield X[ids], y[ids]\n\n\ndef main():\n    seed = 0\n    num_layers = 2\n    hidden_dim = 32\n    num_classes = 10\n    batch_size = 256\n    num_epochs = 10\n    learning_rate = 1e-1\n\n    np.random.seed(seed)\n\n    # Load the data\n    train_images, train_labels, test_images, test_labels = map(mx.array, mnist.mnist())\n\n    # Load the model\n    model = MLP(num_layers, train_images.shape[-1], hidden_dim, num_classes)\n    mx.eval(model.parameters())\n\n    loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n    optimizer = optim.SGD(learning_rate=learning_rate)\n\n    for e in range(num_epochs):\n        tic = time.perf_counter()\n        for X, y in batch_iterate(batch_size, train_images, train_labels):\n            loss, grads = loss_and_grad_fn(model, X, y)\n            optimizer.update(model, grads)\n            mx.eval(model.parameters(), optimizer.state)\n        accuracy = eval_fn(model, test_images, test_labels)\n        toc = time.perf_counter()\n        print(\n            f\"Epoch {e}: Test accuracy {accuracy.item():.3f},\"\n            f\" Time {toc - tic:.3f} (s)\"\n        )\n\nmain()        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}