{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7238394,"sourceType":"datasetVersion","datasetId":4192078},{"sourceId":7240598,"sourceType":"datasetVersion","datasetId":4193656}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import pipeline, set_seed, GPT2Tokenizer,GPT2LMHeadModel, TextDataset, Trainer, TrainingArguments, DataCollatorForLanguageModeling\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T18:14:24.736369Z","iopub.execute_input":"2023-12-19T18:14:24.737275Z","iopub.status.idle":"2023-12-19T18:14:45.299116Z","shell.execute_reply.started":"2023-12-19T18:14:24.737229Z","shell.execute_reply":"2023-12-19T18:14:45.298095Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Finetuning on extract-from-how-google-works book","metadata":{}},{"cell_type":"code","source":"import shutil\n\nsource_file_path = '/kaggle/input/extract-from-how-google-works-eric-schmidt/How Google Works.txt'\ndestination_file_path = '/kaggle/working/How Google Works.txt'\n\n# Copy the file\nshutil.copy(source_file_path, destination_file_path)\n\nprint(f'The file has been copied from {source_file_path} to {destination_file_path}.')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:14:45.301170Z","iopub.execute_input":"2023-12-19T18:14:45.302268Z","iopub.status.idle":"2023-12-19T18:14:45.323852Z","shell.execute_reply.started":"2023-12-19T18:14:45.302215Z","shell.execute_reply":"2023-12-19T18:14:45.322829Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The file has been copied from /kaggle/input/extract-from-how-google-works-eric-schmidt/How Google Works.txt to /kaggle/working/How Google Works.txt.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:14:45.325254Z","iopub.execute_input":"2023-12-19T18:14:45.325621Z","iopub.status.idle":"2023-12-19T18:14:46.548476Z","shell.execute_reply.started":"2023-12-19T18:14:45.325587Z","shell.execute_reply":"2023-12-19T18:14:46.547268Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79f4ba4960f04109b870ceef2166def6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1938de75d8784b8b9e41b1c8593a3fb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68593e801f1a47fdb09d1ff64ad52bf2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c46a5f23084881a6333bbaeac86e3b"}},"metadata":{}}]},{"cell_type":"code","source":"pds_data = TextDataset(\n            tokenizer=tokenizer,\n            file_path='/kaggle/working/How Google Works.txt',\n            block_size=32\n            )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:14:46.551093Z","iopub.execute_input":"2023-12-19T18:14:46.551522Z","iopub.status.idle":"2023-12-19T18:14:48.089959Z","shell.execute_reply.started":"2023-12-19T18:14:46.551484Z","shell.execute_reply":"2023-12-19T18:14:48.089118Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ğŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"pds_data[0],pds_data[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:14:48.091001Z","iopub.execute_input":"2023-12-19T18:14:48.091317Z","iopub.status.idle":"2023-12-19T18:14:48.145830Z","shell.execute_reply.started":"2023-12-19T18:14:48.091291Z","shell.execute_reply":"2023-12-19T18:14:48.145068Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(tensor([44140, 11725,   198, 10962,   286, 26714,   198,  9980, 15653,   198,\n         15269,  7873,   198,   818, 10213,   351,   262,   471,    13,    50,\n            13, 15069,  2191,   286, 15408,    11,   262, 21976,    11, 33794,\n            11,   290]),\n torch.Size([32]))"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:14:48.147034Z","iopub.execute_input":"2023-12-19T18:14:48.147394Z","iopub.status.idle":"2023-12-19T18:14:48.152040Z","shell.execute_reply.started":"2023-12-19T18:14:48.147362Z","shell.execute_reply":"2023-12-19T18:14:48.151164Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = GPT2LMHeadModel.from_pretrained('gpt2')\n\npretrianed_generator = pipeline(\n    'text-generation',model=model,tokenizer='gpt2',\n     config={'max_length':200,'do_sample':True,'top_p':0.9,'temperature':0.7,'top_k':10}   \n)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:22:53.165719Z","iopub.execute_input":"2023-12-19T18:22:53.166618Z","iopub.status.idle":"2023-12-19T18:22:56.542993Z","shell.execute_reply.started":"2023-12-19T18:22:53.166581Z","shell.execute_reply":"2023-12-19T18:22:56.541947Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Intial resposne of model without any context of our book\nfor gen_seq in pretrianed_generator(\"How does data-driven insights contribute to the Google's success \",num_return_sequences=3):\n    print(gen_seq['generated_text'])\n    print(\"===========\")","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:22:58.942201Z","iopub.execute_input":"2023-12-19T18:22:58.942561Z","iopub.status.idle":"2023-12-19T18:23:01.381320Z","shell.execute_reply.started":"2023-12-19T18:22:58.942534Z","shell.execute_reply":"2023-12-19T18:23:01.379463Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"How does data-driven insights contribute to the Google's success \" asked Google's co- alleged co-founder Larry Page III.\n\nPage's response went as follows: \"(I know) I am not the only one who's thought this\n===========\nHow does data-driven insights contribute to the Google's success \" asks Brian Sibbie, Google Analytics Head of Marketing. \"We're looking at the ways people respond to what we know is going on. In those circumstances, we'll look\n===========\nHow does data-driven insights contribute to the Google's success \"\n\nYes, Google's search engine was great. But now, with more and more people looking for that thing, it's more and more difficult for Google to do anything more\n===========\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n                output_dir=\"./gpt2_pds\",\n                overwrite_output_dir = True,\n                num_train_epochs=7,\n                per_device_train_batch_size=32,\n                per_device_eval_batch_size=32,\n                warmup_steps=len(pds_data.examples),\n                logging_steps=50,\n                load_best_model_at_end=True,\n                evaluation_strategy='epoch',\n                save_strategy='epoch'                    \n                )\n\ntrainer = Trainer(\n            model=model,\n            args=training_args,\n            data_collator=data_collator,\n            train_dataset=pds_data.examples[:int(len(pds_data.examples)*.8)], #first 80% of our data\n            eval_dataset=pds_data.examples[int(len(pds_data.examples)*.8):]\n            )","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:14:54.923308Z","iopub.execute_input":"2023-12-19T18:14:54.923934Z","iopub.status.idle":"2023-12-19T18:15:01.708573Z","shell.execute_reply.started":"2023-12-19T18:14:54.923896Z","shell.execute_reply":"2023-12-19T18:15:01.707770Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:15:01.711879Z","iopub.execute_input":"2023-12-19T18:15:01.712215Z","iopub.status.idle":"2023-12-19T18:16:43.524054Z","shell.execute_reply.started":"2023-12-19T18:15:01.712188Z","shell.execute_reply":"2023-12-19T18:16:43.522991Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 01:56]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231219_181612-sd6n3a9e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/greensciverto/huggingface/runs/sd6n3a9e' target=\"_blank\">smooth-cherry-16</a></strong> to <a href='https://wandb.ai/greensciverto/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/greensciverto/huggingface' target=\"_blank\">https://wandb.ai/greensciverto/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/greensciverto/huggingface/runs/sd6n3a9e' target=\"_blank\">https://wandb.ai/greensciverto/huggingface/runs/sd6n3a9e</a>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 4.215001583099365,\n 'eval_runtime': 7.1546,\n 'eval_samples_per_second': 99.377,\n 'eval_steps_per_second': 1.677}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:16:43.525424Z","iopub.execute_input":"2023-12-19T18:16:43.525787Z","iopub.status.idle":"2023-12-19T18:19:26.833724Z","shell.execute_reply.started":"2023-12-19T18:16:43.525752Z","shell.execute_reply":"2023-12-19T18:19:26.832598Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='315' max='315' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [315/315 02:42, Epoch 7/7]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>4.199103</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.411400</td>\n      <td>4.157639</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.333600</td>\n      <td>4.108166</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.215400</td>\n      <td>4.059489</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.120200</td>\n      <td>4.032833</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>4.042500</td>\n      <td>4.012500</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.957000</td>\n      <td>3.997054</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThere were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=315, training_loss=4.169738103472997, metrics={'train_runtime': 162.9273, 'train_samples_per_second': 122.104, 'train_steps_per_second': 1.933, 'total_flos': 324883980288000.0, 'train_loss': 4.169738103472997, 'epoch': 7.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:19:26.835201Z","iopub.execute_input":"2023-12-19T18:19:26.835619Z","iopub.status.idle":"2023-12-19T18:19:28.644560Z","shell.execute_reply.started":"2023-12-19T18:19:26.835561Z","shell.execute_reply":"2023-12-19T18:19:28.643540Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:01]\n    </div>\n    "},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 3.997053861618042,\n 'eval_runtime': 1.7957,\n 'eval_samples_per_second': 395.95,\n 'eval_steps_per_second': 6.683,\n 'epoch': 7.0}"},"metadata":{}}]},{"cell_type":"code","source":"fine_tuned_generator = pipeline(\n    'text-generation',model=model,tokenizer=tokenizer,device=0,\n     config={'max_length':300,'do_sample':True,'top_p':0.9,'temperature':0.7,'top_k':10}   \n)\n\nfor gen_seq in fine_tuned_generator(\"How does data-driven insights contribute to the Google's success \"\",num_return_sequences=3):\n    print(gen_seq['generated_text'])\n    print(\"===========\")","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:21:09.565150Z","iopub.execute_input":"2023-12-19T18:21:09.565752Z","iopub.status.idle":"2023-12-19T18:21:10.153897Z","shell.execute_reply.started":"2023-12-19T18:21:09.565721Z","shell.execute_reply":"2023-12-19T18:21:10.152519Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"How does data-driven insights contribute to the company's success \" asked the CEO.\n \"Let us start with the basic idea,\" said Tim. \"It's like creating a new world, right in your living room. There are sensors and\n===========\nHow does data-driven insights contribute to the company's success  ? What is the process for this? The answer is in the organization.  I think that the best managers want managers who have a strong personal stake in their performance   \n===========\nHow does data-driven insights contribute to the company's success Â or how does the team decide who gets to hire who? The answer is a combination of how important the insights are to the decision making process, but also an understanding of how people\n===========\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Finetuning on LaTex data\nA fine-tuned GPT-2 model that take in the description of an equation in English and output the LaTeX to render that equation.","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nimport pandas as pd\n\ndata = pd.read_csv('/kaggle/input/english-latex-50/equations_dataset.csv')\n\ndata.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:28:08.294353Z","iopub.execute_input":"2023-12-19T18:28:08.295243Z","iopub.status.idle":"2023-12-19T18:28:08.351264Z","shell.execute_reply.started":"2023-12-19T18:28:08.295206Z","shell.execute_reply":"2023-12-19T18:28:08.350403Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                         English                Latex\n0      Integral from 0 to 1 of x   \\int_{0}^{1} x\\,dx\n1  Sum from i equals 1 to n of i     \\sum_{i=1}^{n} i","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Latex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Integral from 0 to 1 of x</td>\n      <td>\\int_{0}^{1} x\\,dx</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sum from i equals 1 to n of i</td>\n      <td>\\sum_{i=1}^{n} i</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token\n\nCONVERSION_PROMPT = 'Latex Conversion Task\\n'\n\nCONVERSION_TOKEN = 'LaTeX:'","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:28:09.523024Z","iopub.execute_input":"2023-12-19T18:28:09.523916Z","iopub.status.idle":"2023-12-19T18:28:09.861273Z","shell.execute_reply.started":"2023-12-19T18:28:09.523882Z","shell.execute_reply":"2023-12-19T18:28:09.860172Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"training_examples = f'{CONVERSION_PROMPT}English: ' + data['English'] + '\\n' + CONVERSION_TOKEN + ' ' + data['Latex'].astype(str)\n\nprint(training_examples[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:28:11.244229Z","iopub.execute_input":"2023-12-19T18:28:11.245023Z","iopub.status.idle":"2023-12-19T18:28:11.257078Z","shell.execute_reply.started":"2023-12-19T18:28:11.244991Z","shell.execute_reply":"2023-12-19T18:28:11.255918Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Latex Conversion Task\nEnglish: Integral from 0 to 1 of x\nLaTeX:  \\int_{0}^{1} x\\,dx\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## \\int_{0}^{1} x\\,dx -> $\\int_{0}^{1} x\\,dx$","metadata":{}},{"cell_type":"code","source":"task_df = pd.DataFrame({'text':training_examples})\n\ntask_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:28:15.723193Z","iopub.execute_input":"2023-12-19T18:28:15.723924Z","iopub.status.idle":"2023-12-19T18:28:15.734981Z","shell.execute_reply.started":"2023-12-19T18:28:15.723893Z","shell.execute_reply":"2023-12-19T18:28:15.733695Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                                text\n0  Latex Conversion Task\\nEnglish: Integral from ...\n1  Latex Conversion Task\\nEnglish: Sum from i equ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Latex Conversion Task\\nEnglish: Integral from ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Latex Conversion Task\\nEnglish: Sum from i equ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"latex_data = Dataset.from_pandas(task_df)\n\ndef preprocess(data):\n        return tokenizer(data['text'], truncation=True)\n    \nlatex_data = latex_data.map(preprocess,batched=True)    \n\nlatex_data = latex_data.train_test_split(train_size=.8)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:28:20.131190Z","iopub.execute_input":"2023-12-19T18:28:20.131549Z","iopub.status.idle":"2023-12-19T18:28:20.325181Z","shell.execute_reply.started":"2023-12-19T18:28:20.131523Z","shell.execute_reply":"2023-12-19T18:28:20.324087Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba4cb12453994022832b944699a9092f"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:28:22.809365Z","iopub.execute_input":"2023-12-19T18:28:22.809722Z","iopub.status.idle":"2023-12-19T18:28:22.816058Z","shell.execute_reply.started":"2023-12-19T18:28:22.809693Z","shell.execute_reply":"2023-12-19T18:28:22.815010Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"latex_gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')\n\ntraining_args = TrainingArguments(\n                output_dir=\"./latex_gpt2\",\n                overwrite_output_dir = True,\n                num_train_epochs=10,\n                per_device_train_batch_size=2,\n                per_device_eval_batch_size=20,                \n                logging_steps=5,\n                log_level='info',\n                load_best_model_at_end=True,\n                evaluation_strategy='epoch',\n                save_strategy='epoch'                    \n                )\n\ntrainer = Trainer(\n            model=latex_gpt2,\n            args=training_args,\n            data_collator=data_collator,\n            train_dataset=latex_data['train'],\n            eval_dataset=latex_data['test']\n            )\n\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:28:26.265639Z","iopub.execute_input":"2023-12-19T18:28:26.265998Z","iopub.status.idle":"2023-12-19T18:28:27.358911Z","shell.execute_reply.started":"2023-12-19T18:28:26.265967Z","shell.execute_reply":"2023-12-19T18:28:27.357674Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 00:09]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 4.243175029754639,\n 'eval_runtime': 0.1162,\n 'eval_samples_per_second': 94.644,\n 'eval_steps_per_second': 8.604}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:28:33.846774Z","iopub.execute_input":"2023-12-19T18:28:33.847610Z","iopub.status.idle":"2023-12-19T18:29:29.154504Z","shell.execute_reply.started":"2023-12-19T18:28:33.847574Z","shell.execute_reply":"2023-12-19T18:29:29.153200Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 41\n  Num Epochs = 10\n  Instantaneous batch size per device = 2\n  Training with DataParallel so batch size has been adjusted to: 4\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 1\n  Total optimization steps = 110\n  Number of trainable parameters = 124,439,808\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [110/110 00:54, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>2.897800</td>\n      <td>1.836686</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.986400</td>\n      <td>1.606321</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.659500</td>\n      <td>1.519372</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.408700</td>\n      <td>1.594503</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.223900</td>\n      <td>1.512287</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.220300</td>\n      <td>1.587681</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.918100</td>\n      <td>1.586797</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.031100</td>\n      <td>1.581843</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.896100</td>\n      <td>1.598251</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.869600</td>\n      <td>1.619587</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-11\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-11/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-11/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-11/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-22\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-22/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-22/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-22/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-33\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-33/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-33/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-33/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-44\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-44/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-44/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-44/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-55\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-55/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-55/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-55/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-66\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-66/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-66/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-66/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-77\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-77/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-77/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-77/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-88\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-88/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-88/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-88/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-99\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-99/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-99/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-99/pytorch_model.bin\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nThe following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 11\n  Batch size = 40\nSaving model checkpoint to ./latex_gpt2/tmp-checkpoint-110\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-110/config.json\nConfiguration saved in ./latex_gpt2/tmp-checkpoint-110/generation_config.json\nModel weights saved in ./latex_gpt2/tmp-checkpoint-110/pytorch_model.bin\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./latex_gpt2/checkpoint-55 (score: 1.5122874975204468).\nThere were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=110, training_loss=1.4559958046132868, metrics={'train_runtime': 54.7292, 'train_samples_per_second': 7.491, 'train_steps_per_second': 2.01, 'total_flos': 10668063744000.0, 'train_loss': 1.4559958046132868, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:19:31.452165Z","iopub.status.idle":"2023-12-19T18:19:31.452504Z","shell.execute_reply.started":"2023-12-19T18:19:31.452343Z","shell.execute_reply":"2023-12-19T18:19:31.452359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_example = 'integral from O to pi of x to the fourth power'\n\nconversion_test_ex = f'{CONVERSION_PROMPT}Eng1ish: {test_example}\\n{CONVERSION_TOKEN}'\n\nprint(conversion_test_ex)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:39:44.730147Z","iopub.execute_input":"2023-12-19T18:39:44.730518Z","iopub.status.idle":"2023-12-19T18:39:44.738272Z","shell.execute_reply.started":"2023-12-19T18:39:44.730487Z","shell.execute_reply":"2023-12-19T18:39:44.736920Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Latex Conversion Task\nEng1ish: integral from O to pi of x to the fourth power\nLaTeX:\n","output_type":"stream"}]},{"cell_type":"code","source":"latex_generator = pipeline(\n    'text-generation',model=latex_gpt2,tokenizer=tokenizer,device=0     \n)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:39:46.543230Z","iopub.execute_input":"2023-12-19T18:39:46.544099Z","iopub.status.idle":"2023-12-19T18:39:46.553034Z","shell.execute_reply.started":"2023-12-19T18:39:46.544064Z","shell.execute_reply":"2023-12-19T18:39:46.552154Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"print(latex_generator(conversion_test_ex,num_beams=5,early_stopping=True,temperature=0.7,max_length=len(tokenizer.encode(conversion_test_ex)) + 20)[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T18:39:53.322508Z","iopub.execute_input":"2023-12-19T18:39:53.322897Z","iopub.status.idle":"2023-12-19T18:39:53.708908Z","shell.execute_reply.started":"2023-12-19T18:39:53.322866Z","shell.execute_reply":"2023-12-19T18:39:53.707711Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Latex Conversion Task\nEng1ish: integral from O to pi of x to the fourth power\nLaTeX:  \\int_{-\\infty}^{\\infty}^{-\\infty}\n","output_type":"stream"}]}]}