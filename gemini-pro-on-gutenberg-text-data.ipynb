{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U sentence-transformers\n!pip -q install google-generativeai==0.3.0\n!pip -q install google-ai-generativelanguage==0.4.0","metadata":{"execution":{"iopub.status.busy":"2023-12-21T18:38:52.519968Z","iopub.execute_input":"2023-12-21T18:38:52.521180Z","iopub.status.idle":"2023-12-21T18:39:41.015379Z","shell.execute_reply.started":"2023-12-21T18:38:52.521107Z","shell.execute_reply":"2023-12-21T18:39:41.014018Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.36.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=e77fe9b7c3010d252ef5f60c8d2fc9e9d2b05574fd2023dcbacf6bfb4f31f56c\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGOOGLE_AI_STUDIO = user_secrets.get_secret(\"GOOGLE_AI_STUDIO\")\n\nimport google.generativeai as genai\n\nfrom IPython.display import display\nfrom IPython.display import Markdown\n\ngenai.configure(api_key=GOOGLE_AI_STUDIO)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T18:39:41.017531Z","iopub.execute_input":"2023-12-21T18:39:41.017873Z","iopub.status.idle":"2023-12-21T18:39:41.953783Z","shell.execute_reply.started":"2023-12-21T18:39:41.017845Z","shell.execute_reply":"2023-12-21T18:39:41.952740Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport requests\n\nfrom bs4 import BeautifulSoup\nfrom urllib.request import urlopen\nfrom datasets import load_dataset\nfrom sentence_transformers import util\nfrom transformers import pipeline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-21T18:39:41.955339Z","iopub.execute_input":"2023-12-21T18:39:41.955951Z","iopub.status.idle":"2023-12-21T18:40:05.156433Z","shell.execute_reply.started":"2023-12-21T18:39:41.955898Z","shell.execute_reply":"2023-12-21T18:40:05.154993Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"text = urlopen('https://www.gutenberg.org/cache/epub/277/pg277.txt').read().decode()\ndocs = list(filter(lambda x: len(x) >100, text.split('\\r\\n\\r\\n')))\ndocs = np.array(docs)\nprint('There are ',len(docs),' documents/para')","metadata":{"execution":{"iopub.status.busy":"2023-12-21T18:40:05.159161Z","iopub.execute_input":"2023-12-21T18:40:05.160415Z","iopub.status.idle":"2023-12-21T18:40:06.150851Z","shell.execute_reply.started":"2023-12-21T18:40:05.160355Z","shell.execute_reply":"2023-12-21T18:40:06.149633Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"There are  95  documents/para\n","output_type":"stream"}]},{"cell_type":"code","source":"model = genai.GenerativeModel('gemini-pro')","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:00:57.614415Z","iopub.execute_input":"2023-12-21T19:00:57.615042Z","iopub.status.idle":"2023-12-21T19:00:57.622089Z","shell.execute_reply.started":"2023-12-21T19:00:57.615000Z","shell.execute_reply":"2023-12-21T19:00:57.620647Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def get_embedding(doc):\n    return genai.embed_content(model='models/embedding-001',content=doc)['embedding']","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:12:29.664667Z","iopub.execute_input":"2023-12-21T19:12:29.665201Z","iopub.status.idle":"2023-12-21T19:12:29.671704Z","shell.execute_reply.started":"2023-12-21T19:12:29.665163Z","shell.execute_reply":"2023-12-21T19:12:29.670222Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"embeddings = [get_embedding(doc) for doc in docs]","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:12:29.674055Z","iopub.execute_input":"2023-12-21T19:12:29.674488Z","iopub.status.idle":"2023-12-21T19:13:13.360221Z","shell.execute_reply.started":"2023-12-21T19:12:29.674453Z","shell.execute_reply":"2023-12-21T19:13:13.358992Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"doc_embeddings = np.array(embeddings)\n\ndoc_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.362387Z","iopub.execute_input":"2023-12-21T19:13:13.363230Z","iopub.status.idle":"2023-12-21T19:13:13.377007Z","shell.execute_reply.started":"2023-12-21T19:13:13.363195Z","shell.execute_reply":"2023-12-21T19:13:13.375962Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"(95, 768)"},"metadata":{}}]},{"cell_type":"code","source":"# QUESTION = 'Why was the name TRINITY given to first detonation of a nuclear weapon?'\nQUESTION = 'Who was J. Robert Oppenheimer?'","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.378862Z","iopub.execute_input":"2023-12-21T19:13:13.379615Z","iopub.status.idle":"2023-12-21T19:13:13.388342Z","shell.execute_reply.started":"2023-12-21T19:13:13.379567Z","shell.execute_reply":"2023-12-21T19:13:13.386988Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"question_embedding = np.array(get_embedding(QUESTION))","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.391375Z","iopub.execute_input":"2023-12-21T19:13:13.392077Z","iopub.status.idle":"2023-12-21T19:13:13.792589Z","shell.execute_reply.started":"2023-12-21T19:13:13.392031Z","shell.execute_reply":"2023-12-21T19:13:13.791369Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"hits = util.semantic_search(question_embedding,doc_embeddings,top_k=3)[0]\nhits","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.793989Z","iopub.execute_input":"2023-12-21T19:13:13.794298Z","iopub.status.idle":"2023-12-21T19:13:13.803259Z","shell.execute_reply.started":"2023-12-21T19:13:13.794269Z","shell.execute_reply":"2023-12-21T19:13:13.802060Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"[{'corpus_id': 17, 'score': 0.7157494501399324},\n {'corpus_id': 14, 'score': 0.7034740733738141},\n {'corpus_id': 41, 'score': 0.6837298329565331}]"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Question : \",QUESTION)\n\nfor i, hit in enumerate(hits):\n    print(f'Document {i+1} Cosine_Similarity_Score {hit[\"score\"]:.3f}:\\n\\n{docs[hit[\"corpus_id\"]]}')\n    print(\"\\n\")    ","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.804780Z","iopub.execute_input":"2023-12-21T19:13:13.805170Z","iopub.status.idle":"2023-12-21T19:13:13.815646Z","shell.execute_reply.started":"2023-12-21T19:13:13.805125Z","shell.execute_reply":"2023-12-21T19:13:13.814494Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Question :  Who was J. Robert Oppenheimer?\nDocument 1 Cosine_Similarity_Score 0.716:\n\nAfter witnessing the awesome blast, Oppenheimer quoted a line from a\nsacred Hindu text, the Bhagavad-Gita: He said: \"I am become death, the\nshatterer of worlds.\"[6] In Los Alamos 230 miles to the north, a group\nof scientists' wives who had stayed up all night for the not so secret\ntest, saw the light and heard the distant sound. One wife, Jane Wilson,\ndescribed it this way, \"Then it came. The blinding light [no] one had\never seen. The trees, illuminated, leaping out. The mountains flashing\ninto life. Later, the long slow rumble. Something had happened, all\nright, for good or ill.\"[7]\n\n\nDocument 2 Cosine_Similarity_Score 0.703:\n\nWorkers built three observation points 5.68 miles (10,000 yards), north,\nsouth, and west of Ground Zero. Code named Able, Baker, and Pittsburgh,\nthese heavily-built wooden bunkers were reinforced with concrete, and\ncovered with earth. The bunker designated Baker or South 10,000 served\nas the control center for the test. This is where head scientist J.\nRobert Oppenheimer would be for the test.\n\n\nDocument 3 Cosine_Similarity_Score 0.684:\n\n[Footnote 6: Kunetka, James W. City of Fire: Los Alamos and the Atomic\nAge, 1943-1945. Albuquerque: University of New Mexico Press, 1978. p.\n170.]\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"context = docs[hits[0]['corpus_id']]\n\nPROMPT = f\"Given the below context, answer the question.\\n\\nContext : {context}\\nQuery: {QUESTION}\\nAnswer:\"","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.817578Z","iopub.execute_input":"2023-12-21T19:13:13.818414Z","iopub.status.idle":"2023-12-21T19:13:13.824791Z","shell.execute_reply.started":"2023-12-21T19:13:13.818373Z","shell.execute_reply":"2023-12-21T19:13:13.823320Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"print(PROMPT)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.826443Z","iopub.execute_input":"2023-12-21T19:13:13.826821Z","iopub.status.idle":"2023-12-21T19:13:13.839321Z","shell.execute_reply.started":"2023-12-21T19:13:13.826770Z","shell.execute_reply":"2023-12-21T19:13:13.838080Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"Given the below context, answer the question.\n\nContext : After witnessing the awesome blast, Oppenheimer quoted a line from a\nsacred Hindu text, the Bhagavad-Gita: He said: \"I am become death, the\nshatterer of worlds.\"[6] In Los Alamos 230 miles to the north, a group\nof scientists' wives who had stayed up all night for the not so secret\ntest, saw the light and heard the distant sound. One wife, Jane Wilson,\ndescribed it this way, \"Then it came. The blinding light [no] one had\never seen. The trees, illuminated, leaping out. The mountains flashing\ninto life. Later, the long slow rumble. Something had happened, all\nright, for good or ill.\"[7]\nQuery: Who was J. Robert Oppenheimer?\nAnswer:\n","output_type":"stream"}]},{"cell_type":"code","source":"generation_config = {\n  \"temperature\": 0.7,\n  \"top_p\": 1,\n  \"top_k\": 1,\n  \"max_output_tokens\": 2048,\n}\n\n\nsafety_settings = [\n  {\n    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n    \"threshold\": \"BLOCK_ONLY_HIGH\"\n  },\n  {\n    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n    \"threshold\": \"BLOCK_ONLY_HIGH\"\n  },\n  {\n    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n    \"threshold\": \"BLOCK_ONLY_HIGH\"\n  },\n  {\n    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n    \"threshold\": \"BLOCK_ONLY_HIGH\"\n  }\n]\n\nmodel = genai.GenerativeModel(model_name=\"gemini-pro\",\n                              generation_config=generation_config,\n                              safety_settings=safety_settings)\n\n\nchat = model.start_chat(history=[])","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.840918Z","iopub.execute_input":"2023-12-21T19:13:13.841333Z","iopub.status.idle":"2023-12-21T19:13:13.849823Z","shell.execute_reply.started":"2023-12-21T19:13:13.841293Z","shell.execute_reply":"2023-12-21T19:13:13.848788Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"chat.send_message(PROMPT)\n\nMarkdown(chat.last.text)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T19:13:13.852865Z","iopub.execute_input":"2023-12-21T19:13:13.853216Z","iopub.status.idle":"2023-12-21T19:13:15.246791Z","shell.execute_reply.started":"2023-12-21T19:13:13.853171Z","shell.execute_reply":"2023-12-21T19:13:15.245599Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The provided context does not mention J. Robert Oppenheimer, so I cannot answer this question from the provided context."},"metadata":{}}]}]}