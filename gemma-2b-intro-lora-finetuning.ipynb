{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-22T11:14:59.051249Z","iopub.execute_input":"2024-02-22T11:14:59.051708Z","iopub.status.idle":"2024-02-22T11:15:28.547747Z","shell.execute_reply.started":"2024-02-22T11:14:59.051667Z","shell.execute_reply":"2024-02-22T11:15:28.546636Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\ntensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:15:28.549793Z","iopub.execute_input":"2024-02-22T11:15:28.550093Z","iopub.status.idle":"2024-02-22T11:15:43.271118Z","shell.execute_reply.started":"2024-02-22T11:15:28.550066Z","shell.execute_reply":"2024-02-22T11:15:43.270146Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-02-22 11:15:30.869555: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-22 11:15:30.869647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-22 11:15:31.029486: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.environ[\"KERAS_BACKEND\"] = \"jax\" ","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:15:43.272255Z","iopub.execute_input":"2024-02-22T11:15:43.272769Z","iopub.status.idle":"2024-02-22T11:15:43.277257Z","shell.execute_reply.started":"2024-02-22T11:15:43.272743Z","shell.execute_reply":"2024-02-22T11:15:43.276191Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the model Gemma 2B\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:15:43.279322Z","iopub.execute_input":"2024-02-22T11:15:43.279670Z","iopub.status.idle":"2024-02-22T11:16:43.837729Z","shell.execute_reply.started":"2024-02-22T11:15:43.279640Z","shell.execute_reply":"2024-02-22T11:16:43.836850Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}]},{"cell_type":"code","source":"gemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:16:43.838858Z","iopub.execute_input":"2024-02-22T11:16:43.839186Z","iopub.status.idle":"2024-02-22T11:16:44.053908Z","shell.execute_reply.started":"2024-02-22T11:16:43.839150Z","shell.execute_reply":"2024-02-22T11:16:44.053002Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"gemma_lm.generate(\"How does ChatGPT work, does it use a MOE architecture?\", max_length=128)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:17:05.073751Z","iopub.execute_input":"2024-02-22T11:17:05.074609Z","iopub.status.idle":"2024-02-22T11:17:32.161841Z","shell.execute_reply.started":"2024-02-22T11:17:05.074577Z","shell.execute_reply":"2024-02-22T11:17:32.160856Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1708600647.181246      34 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1708600647.245259      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1708600647.445713      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'How does ChatGPT work, does it use a MOE architecture?\\n\\nI’m not sure if it’s a MOE architecture, but it’s definitely a transformer architecture.\\n\\nI’m not sure if it’s a MOE architecture, but it’s definitely a transformer architecture.\\n\\nI’m not sure if it’s a MOE architecture, but it’s definitely a transformer architecture.\\n\\nI’m not sure if it’s a MOE architecture, but it’s definitely a transformer architecture.\\n\\nI’m not sure if it’s a MOE architecture, but it’'"},"metadata":{}}]},{"cell_type":"code","source":"gemma_lm.compile(sampler=\"top_k\")\n\nfrom IPython.display import Markdown\nMarkdown(gemma_lm.generate(\"Why should one use a MOE architecture?\", max_length=250))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:23:07.749934Z","iopub.execute_input":"2024-02-22T11:23:07.750804Z","iopub.status.idle":"2024-02-22T11:23:43.640259Z","shell.execute_reply.started":"2024-02-22T11:23:07.750772Z","shell.execute_reply":"2024-02-22T11:23:43.639167Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"W0000 00:00:1708601013.447389      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Why should one use a MOE architecture?\n\n* MOE is the most common and the most reliable type of architecture used in the industry.\n* MOE is the most cost efficient architecture.\n* The design of a MOE system is simple.\n* It is very easy to implement and maintain.\n* MOE systems are very reliable.\n* MOE systems are very flexible.\n\nWhat are the advantages of using a MOE architecture?\n\n* The MOE architecture is the easiest architecture for a system to be implemented in, as it is the simplest architecture.\n* The MOE architecture is the cheapest architecture to implement, as it has fewer components than any other architecture.\n* The MOE architecture is the easiest architecture to maintain as it has the simplest system of parts, and therefore the fewest parts to maintain.\n* The MOE architecture is the most reliable of all architectures, because it has no moving parts.\n* The MOE architecture is flexible, because it is a modular architecture.\n  A system can be expanded or contracted to meet any demand.\n* The MOE architecture is the most adaptable architecture, because any part of it can be changed without affecting the rest of the system."},"metadata":{}}]},{"cell_type":"markdown","source":"### Low Rank Adaptation (LoRA) is a fine-tuning technique which greatly reduces the number of trainable parameters for downstream tasks by freezing the weights of the model and inserting a smaller number of new weights into the model.\n\nThe LoRA rank determines the dimensionality of the trainable matrices that are added to the original weights of the LLM. It controls the expressiveness and precision of the fine-tuning adjustments.\n\nA higher rank means more detailed changes are possible, but also means more trainable parameters. A lower rank means less computational overhead, but potentially less precise adaptation","metadata":{}},{"cell_type":"code","source":"os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:26:35.459330Z","iopub.execute_input":"2024-02-22T11:26:35.459714Z","iopub.status.idle":"2024-02-22T11:26:35.466353Z","shell.execute_reply.started":"2024-02-22T11:26:35.459685Z","shell.execute_reply":"2024-02-22T11:26:35.465428Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### Dataset : Databricks Dolly 15k dataset. This dataset contains 15,000 high-quality human-generated prompt / response pairs specifically designed for fine-tuning LLMs.","metadata":{}},{"cell_type":"code","source":"!wget -O databricks-dolly-15k.jsonl https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:28:10.140567Z","iopub.execute_input":"2024-02-22T11:28:10.141267Z","iopub.status.idle":"2024-02-22T11:28:11.507931Z","shell.execute_reply.started":"2024-02-22T11:28:10.141235Z","shell.execute_reply":"2024-02-22T11:28:11.506961Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"--2024-02-22 11:28:11--  https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl\nResolving huggingface.co (huggingface.co)... 18.172.134.24, 18.172.134.4, 18.172.134.88, ...\nConnecting to huggingface.co (huggingface.co)|18.172.134.24|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs.huggingface.co/repos/34/ac/34ac588cc580830664f592597bb6d19d61639eca33dc2d6bb0b6d833f7bfd552/2df9083338b4abd6bceb5635764dab5d833b393b55759dffb0959b6fcbf794ec?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27databricks-dolly-15k.jsonl%3B+filename%3D%22databricks-dolly-15k.jsonl%22%3B&Expires=1708860491&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwODg2MDQ5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8zNC9hYy8zNGFjNTg4Y2M1ODA4MzA2NjRmNTkyNTk3YmI2ZDE5ZDYxNjM5ZWNhMzNkYzJkNmJiMGI2ZDgzM2Y3YmZkNTUyLzJkZjkwODMzMzhiNGFiZDZiY2ViNTYzNTc2NGRhYjVkODMzYjM5M2I1NTc1OWRmZmIwOTU5YjZmY2JmNzk0ZWM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=RQQT5MvBu31BKS5ghUV%7E0mouT1n-MS9YmRnCNpmcnsEEzPSSrBROjJnyoQ87KwXnMdNZI3-Dgvt07DVOeZPsxvBZau4i4hsmFlvTMm3w-IZnTTkKJDJy5AoMROulZXFAEMUNL0dpFcg72Ih35D3aPcaQs2IfNXWSw5XSzEks6DBdDdLUgHp%7EBYAUt%7EM2cfW0kfutiLynud1FIhhBtG23Tzc-8QZhd5yNe7A7V71hAitjztiz3x7AwCATnEnQQgtxwnN41gJ1USsVAcWyHky0KFSjYShGzqlinnFlswx%7EIA99qeDXh6eQY3kPE%7Ednpo186J5oRrRkvZFYT3CjCCsEAQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n--2024-02-22 11:28:11--  https://cdn-lfs.huggingface.co/repos/34/ac/34ac588cc580830664f592597bb6d19d61639eca33dc2d6bb0b6d833f7bfd552/2df9083338b4abd6bceb5635764dab5d833b393b55759dffb0959b6fcbf794ec?response-content-disposition=attachment%3B+filename*%3DUTF-8''databricks-dolly-15k.jsonl%3B+filename%3D%22databricks-dolly-15k.jsonl%22%3B&Expires=1708860491&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwODg2MDQ5MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8zNC9hYy8zNGFjNTg4Y2M1ODA4MzA2NjRmNTkyNTk3YmI2ZDE5ZDYxNjM5ZWNhMzNkYzJkNmJiMGI2ZDgzM2Y3YmZkNTUyLzJkZjkwODMzMzhiNGFiZDZiY2ViNTYzNTc2NGRhYjVkODMzYjM5M2I1NTc1OWRmZmIwOTU5YjZmY2JmNzk0ZWM~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=RQQT5MvBu31BKS5ghUV~0mouT1n-MS9YmRnCNpmcnsEEzPSSrBROjJnyoQ87KwXnMdNZI3-Dgvt07DVOeZPsxvBZau4i4hsmFlvTMm3w-IZnTTkKJDJy5AoMROulZXFAEMUNL0dpFcg72Ih35D3aPcaQs2IfNXWSw5XSzEks6DBdDdLUgHp~BYAUt~M2cfW0kfutiLynud1FIhhBtG23Tzc-8QZhd5yNe7A7V71hAitjztiz3x7AwCATnEnQQgtxwnN41gJ1USsVAcWyHky0KFSjYShGzqlinnFlswx~IA99qeDXh6eQY3kPE~dnpo186J5oRrRkvZFYT3CjCCsEAQ__&Key-Pair-Id=KVTP0A1DKRTAX\nResolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.160.225.43, 18.160.225.20, 18.160.225.8, ...\nConnecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.160.225.43|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 13085339 (12M) [text/plain]\nSaving to: 'databricks-dolly-15k.jsonl'\n\ndatabricks-dolly-15 100%[===================>]  12.48M  --.-KB/s    in 0.1s    \n\n2024-02-22 11:28:11 (105 MB/s) - 'databricks-dolly-15k.jsonl' saved [13085339/13085339]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## a subset of 1000 training examples\n\nimport json\ndata = []\nwith open(\"databricks-dolly-15k.jsonl\") as file:\n    for line in file:\n        features = json.loads(line)\n        # Filter out examples with context, to keep it simple.\n        if features[\"context\"]:\n            continue\n        # Format the entire example as a single string.\n        template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n        data.append(template.format(**features))\n\n# Only use 1000 training examples, to keep it fast.\ndata = data[:1000]","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:28:50.363141Z","iopub.execute_input":"2024-02-22T11:28:50.363533Z","iopub.status.idle":"2024-02-22T11:28:50.520076Z","shell.execute_reply.started":"2024-02-22T11:28:50.363502Z","shell.execute_reply":"2024-02-22T11:28:50.519353Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data[:5]","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:29:20.994836Z","iopub.execute_input":"2024-02-22T11:29:20.995220Z","iopub.status.idle":"2024-02-22T11:29:21.001316Z","shell.execute_reply.started":"2024-02-22T11:29:20.995193Z","shell.execute_reply":"2024-02-22T11:29:21.000345Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['Instruction:\\nWhich is a species of fish? Tope or Rope\\n\\nResponse:\\nTope',\n 'Instruction:\\nWhy can camels survive for long without water?\\n\\nResponse:\\nCamels use the fat in their humps to keep them filled with energy and hydration for long periods of time.',\n \"Instruction:\\nAlice's parents have three daughters: Amy, Jessy, and what’s the name of the third daughter?\\n\\nResponse:\\nThe name of the third daughter is Alice\",\n 'Instruction:\\nWho gave the UN the land in NY to build their HQ\\n\\nResponse:\\nJohn D Rockerfeller',\n 'Instruction:\\nWhy mobile is bad for human\\n\\nResponse:\\nWe are always engaged one phone which is not good.']"},"metadata":{}}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"What should I do on a trip to Germany?\",\n    response=\"\",\n)\nsampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:30:34.554040Z","iopub.execute_input":"2024-02-22T11:30:34.554960Z","iopub.status.idle":"2024-02-22T11:31:10.180058Z","shell.execute_reply.started":"2024-02-22T11:30:34.554928Z","shell.execute_reply":"2024-02-22T11:31:10.179069Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"W0000 00:00:1708601459.987161      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"Instruction:\nWhat should I do on a trip to Germany?\n\nResponse:\n1. Take a look at the German flag.\n\n2. Say “Guten Tag” (good day) to everyone you meet.\n\n3. Say “danke” (thank you) after every meal.\n\n4. Ask about the German language.\n\n5. Say the German alphabet.\n\n6. Say “Guten Tag!” (good day) and “danke” (thank you) when you meet someone new.\n\n7. Find a German phrase book at your local library.\n\n8. Learn how to pronounce the German alphabet (a-b-c-d-e-f-g-h-i-j-k-l-m-n-o-o-p-q-r-s-t-u-v-w-x-y-z).\n\n9. Find an old-fashioned German dictionary at a second-hand book shop.\n\n10. Look at the German calendar.\n\n11. Learn how to say “good morning,” “good night,” and “good afternoon” in German.\n\n12. Learn the German greeting “guten Tag” and the German goodbye “schlepp.”\n\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"Explain the process of Low Rank Adaptation (LoRA) in a way that a child could understand.\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:33:02.514429Z","iopub.execute_input":"2024-02-22T11:33:02.514789Z","iopub.status.idle":"2024-02-22T11:33:12.295094Z","shell.execute_reply.started":"2024-02-22T11:33:02.514764Z","shell.execute_reply":"2024-02-22T11:33:12.294052Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Instruction:\nExplain the process of Low Rank Adaptation (LoRA) in a way that a child could understand.\n\nResponse:\nLow Rank Adaptation (LoRA) in a way that a child could understand.\nLoRA can be explained with the help of the following steps.\n1. First the low rank matrix is created using SVD (Singular Value Decomposition) method.\n2. After the low rank matrix is created, then the low rank matrix is used to generate a low rank approximation.\n3. The low rank matrix is then used to generate a low rank approximation.\n4. The matrix is then used to generate a low rank approximation.\n5. Finally, the matrix is used to generate a low rank approximation.\n\nExplanation:\nIn this method, the matrix is first decomposed into two matrices, a low rank approximation and a matrix with a higher rank. The low rank approximation matrix is then used to generate a low rank approximation. The matrix is then used to generate a low rank approximation. The result is a low rank approximation matrix.\n\n<h3>How to Use Low Rank Matrix</h3>\n\nThe low rank matrix is used to generate a low rank approximation. The low rank matrix is then used to generate a low rank approximation. The low rank matrix\n","output_type":"stream"}]},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 4.\n# enabling LoRA reduces the number of trainable parameters significantly (from 2.5 billion to 1.3 million).\ngemma_lm.backbone.enable_lora(rank=4)\ngemma_lm.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:33:20.961527Z","iopub.execute_input":"2024-02-22T11:33:20.961882Z","iopub.status.idle":"2024-02-22T11:33:21.114380Z","shell.execute_reply.started":"2024-02-22T11:33:20.961855Z","shell.execute_reply":"2024-02-22T11:33:21.113498Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Limit the input sequence length to 256 (to control memory usage).\ngemma_lm.preprocessor.sequence_length = 256\n# Use AdamW (a common optimizer for transformer models).\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\n# Exclude layernorm and bias terms from decay.\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\ngemma_lm.fit(data, epochs=1, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:40:55.922638Z","iopub.execute_input":"2024-02-22T11:40:55.923418Z","iopub.status.idle":"2024-02-22T11:53:36.124670Z","shell.execute_reply.started":"2024-02-22T11:40:55.923387Z","shell.execute_reply":"2024-02-22T11:53:36.123733Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"W0000 00:00:1708602100.767818     175 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m760s\u001b[0m 715ms/step - loss: nan - sparse_categorical_accuracy: nan\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7e6cfdeee800>"},"metadata":{}}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"What should I do on a trip to Norway?\",\n    response=\"\",\n)\nsampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\ngemma_lm.compile(sampler=sampler)\nprint(gemma_lm.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:56:05.218914Z","iopub.execute_input":"2024-02-22T11:56:05.219847Z","iopub.status.idle":"2024-02-22T11:56:40.965223Z","shell.execute_reply.started":"2024-02-22T11:56:05.219817Z","shell.execute_reply":"2024-02-22T11:56:40.964144Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"W0000 00:00:1708602989.410676      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"Instruction:\nWhat should I do on a trip to Norway?\n\nResponse:\n鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"Explain the process of Low Rank Adaptation (LoRA) in a way that a child could understand.\",\n    response=\"\",\n)\nprint(gemma_lm.generate(prompt, max_length=64))","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:57:52.545915Z","iopub.execute_input":"2024-02-22T11:57:52.546896Z","iopub.status.idle":"2024-02-22T11:58:18.571046Z","shell.execute_reply.started":"2024-02-22T11:57:52.546865Z","shell.execute_reply":"2024-02-22T11:58:18.570050Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"W0000 00:00:1708603096.741157      34 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"Instruction:\nExplain the process of Low Rank Adaptation (LoRA) in a way that a child could understand.\n\nResponse:\n鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪鵪\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gputil\n\nimport GPUtil\n\n# Get the list of available GPUs\ngpus = GPUtil.getGPUs()\n\nfor gpu in gpus:\n    print(\"GPU ID:\", gpu.id)\n    print(\"GPU Name:\", gpu.name)\n    print(\"GPU Memory Utilization:\", gpu.memoryUtil * 100, \"%\")\n    print(\"GPU Memory Used:\", gpu.memoryUsed, \"MB\")\n    print(\"GPU Memory Free:\", gpu.memoryFree, \"MB\")\n    print(\"GPU Temperature:\", gpu.temperature, \"C\")","metadata":{"execution":{"iopub.status.busy":"2024-02-22T11:58:33.781118Z","iopub.execute_input":"2024-02-22T11:58:33.782152Z","iopub.status.idle":"2024-02-22T11:58:48.516239Z","shell.execute_reply.started":"2024-02-22T11:58:33.782101Z","shell.execute_reply":"2024-02-22T11:58:48.515100Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Collecting gputil\n  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: gputil\n  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=877b73578576960926726e2349e0ab9ff241e12086a7ee3c8a1ff2d98d8a05c3\n  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\nSuccessfully built gputil\nInstalling collected packages: gputil\nSuccessfully installed gputil-1.4.0\nGPU ID: 0\nGPU Name: Tesla T4\nGPU Memory Utilization: 92.44140625 %\nGPU Memory Used: 14199.0 MB\nGPU Memory Free: 903.0 MB\nGPU Temperature: 75.0 C\nGPU ID: 1\nGPU Name: Tesla T4\nGPU Memory Utilization: 0.6705729166666666 %\nGPU Memory Used: 103.0 MB\nGPU Memory Free: 14999.0 MB\nGPU Temperature: 62.0 C\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}